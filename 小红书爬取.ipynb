{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 自定义要搜索的关键词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 要搜索的字段\n",
    "text = '皮带'\n",
    "\n",
    "# 一共要爬取的数量\n",
    "totalnum = 10\n",
    "\n",
    "\n",
    "# 【这一步需要提前手动操作】\n",
    "# 运行cmd命令\n",
    "# 输入后面的代码，把【chrome.exe】替换成你的谷歌浏览器的地址 #  chrome.exe --remote-debugging-port=9222 --user-data-dir=\"C:\\selenum\\AutomationProfile\"\n",
    "# 就像这样 # \"C:\\Users\\lenovo\\Desktop\\chrome-win64\\chrome.exe\" --remote-debugging-port=9222 --user-data-dir=\"C:\\selenum\\AutomationProfile\"\n",
    "#\"C:\\Users\\lenovo\\Desktop\\chrome-win64\\chrome.exe\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 一、实例化selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在这里下载合适的版本 \n",
    "# https://chromedriver.chromium.org/home\n",
    "# https://googlechromelabs.github.io/chrome-for-testing/\n",
    "\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from tqdm import tqdm\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "\n",
    "import time\n",
    "from scrapy.selector import Selector\n",
    "import json\n",
    "import os\n",
    "\n",
    "\n",
    "options = Options()\n",
    "options.add_experimental_option('debuggerAddress', '127.0.0.1:9222')\n",
    "options.add_argument('--incognito')  # 隐身模式（无痕模式）\n",
    "options.add_argument('blink-settings=imagesEnabled=false')  # 不加载图片, 提升速度\n",
    "browser = webdriver.Chrome(options=options)\n",
    "# 设置 ChromeDriver 的路径\n",
    "service = Service(\"C:/Users/lenovo/Desktop/xiaohongshu/chromedriver.exe\")  # 替换为你的实际路径\n",
    "browser = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "#\"C:\\Users\\lenovo\\Desktop\\xiaohongshu\\chromedriver.exe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Nov 24 12:00:56 2024 : 登录成功！！！\n",
      "Sun Nov 24 12:01:08 2024 : 加载成功！！！\n"
     ]
    }
   ],
   "source": [
    "# 要搜索的字段\n",
    "text = text\n",
    "\n",
    "# 一共要爬取的数量\n",
    "totalnum = totalnum\n",
    "\n",
    "# 打开网页\n",
    "browser.get('https://www.xiaohongshu.com/explore')\n",
    "\n",
    "# 判断是否登录\n",
    "while True:\n",
    "    page_source = browser.page_source\n",
    "    if '登录探索更多内容' in page_source:\n",
    "        time.sleep(2)\n",
    "        print('%s : 未登录，请手动登录小红书！！！' % time.ctime())\n",
    "        continue\n",
    "    else:\n",
    "        print('%s : 登录成功！！！' % time.ctime())\n",
    "        time.sleep(3)\n",
    "        break\n",
    "\n",
    "# 打开网址\n",
    "url = r'https://www.xiaohongshu.com/search_result?keyword=%s&source=web_explore_feed' % text\n",
    "browser.get(url)\n",
    "time.sleep(2)\n",
    "\n",
    "# 等待加载\n",
    "while True:\n",
    "    if text in browser.title:\n",
    "        print('%s : 加载成功！！！' % time.ctime())\n",
    "        break\n",
    "    else:\n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'totalnum' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m     itemCodeList \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# 定义进度条\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m totalnum \u001b[38;5;241m=\u001b[39m totalnum \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(itemCodeList)\n\u001b[0;32m     18\u001b[0m qbar \u001b[38;5;241m=\u001b[39m tqdm(total\u001b[38;5;241m=\u001b[39mtotalnum)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# 解析网页\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'totalnum' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from scrapy.selector import Selector\n",
    "import time\n",
    "\n",
    "# 先加载已经存储的\n",
    "if os.path.exists('_items.txt'):\n",
    "    with open('_items.txt', 'r', encoding='utf-8') as f:\n",
    "        items = f.readlines()\n",
    "    items = [json.loads(item.strip()) for item in items if item.strip()]  # 确保每行都有内容\n",
    "    itemCodeList = [item['code'] for item in items]\n",
    "else:\n",
    "    itemCodeList = []\n",
    "\n",
    "# 定义进度条\n",
    "totalnum = totalnum - len(itemCodeList)\n",
    "qbar = tqdm(total=totalnum)\n",
    "\n",
    "# 解析网页\n",
    "def parsePage(text):\n",
    "    selector = Selector(text=text)\n",
    "    # 使用更宽松的 XPath 匹配\n",
    "    divs = selector.xpath('//section[contains(@class, \"note-item\")]')\n",
    "    if not divs:\n",
    "        print(\"No items found on page.\")\n",
    "        return\n",
    "\n",
    "    for div in divs:\n",
    "        item = {}\n",
    "        try:\n",
    "            # 提取数据\n",
    "            item['title'] = div.xpath('.//a[@class=\"title\"]/span/text()').extract_first()\n",
    "            item['user'] = div.xpath('.//a[@class=\"author\"]//span[@class=\"name\"]/text()').extract_first()\n",
    "            like_num = div.xpath('.//span[@class=\"count\"]/text()').extract_first()\n",
    "            item['likeNum'] = like_num.strip() if like_num else \"0\"\n",
    "            href = div.xpath('.//a[@class=\"cover mask\"]/@href').extract_first()\n",
    "            if not href:\n",
    "                href = div.xpath('.//a/@href').extract_first()  # 备用路径\n",
    "            if not href:\n",
    "                raise ValueError(\"Missing href\")\n",
    "            item['code'] = href.split('/')[-1]\n",
    "\n",
    "            # 保存数据\n",
    "            if item['code'] not in itemCodeList:\n",
    "                itemCodeList.append(item['code'])\n",
    "                with open('_items.txt', 'a+', encoding='utf-8') as f:\n",
    "                    f.write(json.dumps(item, ensure_ascii=False) + '\\n')\n",
    "                qbar.update(1)\n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing item: {e}\")\n",
    "\n",
    "\n",
    "# 爬取数据\n",
    "while len(itemCodeList) < totalnum:\n",
    "    if '- THE END -' in browser.page_source:\n",
    "        print('- THE END -')\n",
    "        break\n",
    "\n",
    "    parsePage(text=browser.page_source)\n",
    "    time.sleep(0.3)\n",
    "    # 滚到底部\n",
    "    browser.execute_script('window.scrollTo(0, document.body.scrollHeight)')\n",
    "    time.sleep(2)\n",
    "\n",
    "qbar.close()\n",
    "print(\"Crawling completed!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 三、抓取详情页"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: selenium-stealth in d:\\anaconda3\\lib\\site-packages (1.0.6)\n",
      "Requirement already satisfied: selenium in d:\\anaconda3\\lib\\site-packages (from selenium-stealth) (4.21.0)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in d:\\anaconda3\\lib\\site-packages (from selenium->selenium-stealth) (2024.8.30)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in d:\\anaconda3\\lib\\site-packages (from selenium->selenium-stealth) (0.11.1)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in d:\\anaconda3\\lib\\site-packages (from selenium->selenium-stealth) (4.12.2)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in d:\\anaconda3\\lib\\site-packages (from selenium->selenium-stealth) (1.26.11)\n",
      "Requirement already satisfied: trio~=0.17 in d:\\anaconda3\\lib\\site-packages (from selenium->selenium-stealth) (0.23.1)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in d:\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium->selenium-stealth) (1.3.0)\n",
      "Requirement already satisfied: idna in d:\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium->selenium-stealth) (3.3)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in d:\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium->selenium-stealth) (1.2.0)\n",
      "Requirement already satisfied: sortedcontainers in d:\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium->selenium-stealth) (2.4.0)\n",
      "Requirement already satisfied: attrs>=20.1.0 in d:\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium->selenium-stealth) (21.4.0)\n",
      "Requirement already satisfied: outcome in d:\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium->selenium-stealth) (1.3.0.post0)\n",
      "Requirement already satisfied: cffi>=1.14 in d:\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium->selenium-stealth) (1.15.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in d:\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium->selenium-stealth) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in d:\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium->selenium-stealth) (1.7.1)\n",
      "Requirement already satisfied: pycparser in d:\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium->selenium-stealth) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in d:\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium->selenium-stealth) (0.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install selenium-stealth\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "没有反爬虫肯定可以爬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/102 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load page for code 64c527d3000000001700ed8a: Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF796CC6CB5+28821]\n",
      "\t(No symbol) [0x00007FF796C33840]\n",
      "\t(No symbol) [0x00007FF796AD578A]\n",
      "\t(No symbol) [0x00007FF796B291BE]\n",
      "\t(No symbol) [0x00007FF796B294AC]\n",
      "\t(No symbol) [0x00007FF796B72647]\n",
      "\t(No symbol) [0x00007FF796B4F33F]\n",
      "\t(No symbol) [0x00007FF796B6F412]\n",
      "\t(No symbol) [0x00007FF796B4F0A3]\n",
      "\t(No symbol) [0x00007FF796B1A778]\n",
      "\t(No symbol) [0x00007FF796B1B8E1]\n",
      "\tGetHandleVerifier [0x00007FF796FFFCAD+3408013]\n",
      "\tGetHandleVerifier [0x00007FF79701741F+3504127]\n",
      "\tGetHandleVerifier [0x00007FF79700B5FD+3455453]\n",
      "\tGetHandleVerifier [0x00007FF796D8BDBB+835995]\n",
      "\t(No symbol) [0x00007FF796C3EB5F]\n",
      "\t(No symbol) [0x00007FF796C3A814]\n",
      "\t(No symbol) [0x00007FF796C3A9AD]\n",
      "\t(No symbol) [0x00007FF796C2A199]\n",
      "\tBaseThreadInitThunk [0x00007FFB9355259D+29]\n",
      "\tRtlUserThreadStart [0x00007FFB9444AF38+40]\n",
      "\n",
      "Failed to load page for code 649c1e74000000001300e49b: Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF796CC6CB5+28821]\n",
      "\t(No symbol) [0x00007FF796C33840]\n",
      "\t(No symbol) [0x00007FF796AD578A]\n",
      "\t(No symbol) [0x00007FF796B291BE]\n",
      "\t(No symbol) [0x00007FF796B294AC]\n",
      "\t(No symbol) [0x00007FF796B72647]\n",
      "\t(No symbol) [0x00007FF796B4F33F]\n",
      "\t(No symbol) [0x00007FF796B6F412]\n",
      "\t(No symbol) [0x00007FF796B4F0A3]\n",
      "\t(No symbol) [0x00007FF796B1A778]\n",
      "\t(No symbol) [0x00007FF796B1B8E1]\n",
      "\tGetHandleVerifier [0x00007FF796FFFCAD+3408013]\n",
      "\tGetHandleVerifier [0x00007FF79701741F+3504127]\n",
      "\tGetHandleVerifier [0x00007FF79700B5FD+3455453]\n",
      "\tGetHandleVerifier [0x00007FF796D8BDBB+835995]\n",
      "\t(No symbol) [0x00007FF796C3EB5F]\n",
      "\t(No symbol) [0x00007FF796C3A814]\n",
      "\t(No symbol) [0x00007FF796C3A9AD]\n",
      "\t(No symbol) [0x00007FF796C2A199]\n",
      "\tBaseThreadInitThunk [0x00007FFB9355259D+29]\n",
      "\tRtlUserThreadStart [0x00007FFB9444AF38+40]\n",
      "\n",
      "Failed to load page for code 647fff9d0000000013010294: Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF796CC6CB5+28821]\n",
      "\t(No symbol) [0x00007FF796C33840]\n",
      "\t(No symbol) [0x00007FF796AD578A]\n",
      "\t(No symbol) [0x00007FF796B291BE]\n",
      "\t(No symbol) [0x00007FF796B294AC]\n",
      "\t(No symbol) [0x00007FF796B72647]\n",
      "\t(No symbol) [0x00007FF796B4F33F]\n",
      "\t(No symbol) [0x00007FF796B6F412]\n",
      "\t(No symbol) [0x00007FF796B4F0A3]\n",
      "\t(No symbol) [0x00007FF796B1A778]\n",
      "\t(No symbol) [0x00007FF796B1B8E1]\n",
      "\tGetHandleVerifier [0x00007FF796FFFCAD+3408013]\n",
      "\tGetHandleVerifier [0x00007FF79701741F+3504127]\n",
      "\tGetHandleVerifier [0x00007FF79700B5FD+3455453]\n",
      "\tGetHandleVerifier [0x00007FF796D8BDBB+835995]\n",
      "\t(No symbol) [0x00007FF796C3EB5F]\n",
      "\t(No symbol) [0x00007FF796C3A814]\n",
      "\t(No symbol) [0x00007FF796C3A9AD]\n",
      "\t(No symbol) [0x00007FF796C2A199]\n",
      "\tBaseThreadInitThunk [0x00007FFB9355259D+29]\n",
      "\tRtlUserThreadStart [0x00007FFB9444AF38+40]\n",
      "\n",
      "Failed to load page for code 648409780000000027003869: Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF796CC6CB5+28821]\n",
      "\t(No symbol) [0x00007FF796C33840]\n",
      "\t(No symbol) [0x00007FF796AD578A]\n",
      "\t(No symbol) [0x00007FF796B291BE]\n",
      "\t(No symbol) [0x00007FF796B294AC]\n",
      "\t(No symbol) [0x00007FF796B72647]\n",
      "\t(No symbol) [0x00007FF796B4F33F]\n",
      "\t(No symbol) [0x00007FF796B6F412]\n",
      "\t(No symbol) [0x00007FF796B4F0A3]\n",
      "\t(No symbol) [0x00007FF796B1A778]\n",
      "\t(No symbol) [0x00007FF796B1B8E1]\n",
      "\tGetHandleVerifier [0x00007FF796FFFCAD+3408013]\n",
      "\tGetHandleVerifier [0x00007FF79701741F+3504127]\n",
      "\tGetHandleVerifier [0x00007FF79700B5FD+3455453]\n",
      "\tGetHandleVerifier [0x00007FF796D8BDBB+835995]\n",
      "\t(No symbol) [0x00007FF796C3EB5F]\n",
      "\t(No symbol) [0x00007FF796C3A814]\n",
      "\t(No symbol) [0x00007FF796C3A9AD]\n",
      "\t(No symbol) [0x00007FF796C2A199]\n",
      "\tBaseThreadInitThunk [0x00007FFB9355259D+29]\n",
      "\tRtlUserThreadStart [0x00007FFB9444AF38+40]\n",
      "\n",
      "Failed to load page for code 6514d6b0000000001a01765c: Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF796CC6CB5+28821]\n",
      "\t(No symbol) [0x00007FF796C33840]\n",
      "\t(No symbol) [0x00007FF796AD578A]\n",
      "\t(No symbol) [0x00007FF796B291BE]\n",
      "\t(No symbol) [0x00007FF796B294AC]\n",
      "\t(No symbol) [0x00007FF796B72647]\n",
      "\t(No symbol) [0x00007FF796B4F33F]\n",
      "\t(No symbol) [0x00007FF796B6F412]\n",
      "\t(No symbol) [0x00007FF796B4F0A3]\n",
      "\t(No symbol) [0x00007FF796B1A778]\n",
      "\t(No symbol) [0x00007FF796B1B8E1]\n",
      "\tGetHandleVerifier [0x00007FF796FFFCAD+3408013]\n",
      "\tGetHandleVerifier [0x00007FF79701741F+3504127]\n",
      "\tGetHandleVerifier [0x00007FF79700B5FD+3455453]\n",
      "\tGetHandleVerifier [0x00007FF796D8BDBB+835995]\n",
      "\t(No symbol) [0x00007FF796C3EB5F]\n",
      "\t(No symbol) [0x00007FF796C3A814]\n",
      "\t(No symbol) [0x00007FF796C3A9AD]\n",
      "\t(No symbol) [0x00007FF796C2A199]\n",
      "\tBaseThreadInitThunk [0x00007FFB9355259D+29]\n",
      "\tRtlUserThreadStart [0x00007FFB9444AF38+40]\n",
      "\n",
      "Failed to load page for code 65299cdb000000001e02c7d5: Message: no such window: target window already closed\n",
      "from unknown error: web view not found\n",
      "  (Session info: chrome=131.0.6778.85)\n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF796CC6CB5+28821]\n",
      "\t(No symbol) [0x00007FF796C33840]\n",
      "\t(No symbol) [0x00007FF796AD578A]\n",
      "\t(No symbol) [0x00007FF796AAF4F5]\n",
      "\t(No symbol) [0x00007FF796B56247]\n",
      "\t(No symbol) [0x00007FF796B6ECE2]\n",
      "\t(No symbol) [0x00007FF796B4F0A3]\n",
      "\t(No symbol) [0x00007FF796B1A778]\n",
      "\t(No symbol) [0x00007FF796B1B8E1]\n",
      "\tGetHandleVerifier [0x00007FF796FFFCAD+3408013]\n",
      "\tGetHandleVerifier [0x00007FF79701741F+3504127]\n",
      "\tGetHandleVerifier [0x00007FF79700B5FD+3455453]\n",
      "\tGetHandleVerifier [0x00007FF796D8BDBB+835995]\n",
      "\t(No symbol) [0x00007FF796C3EB5F]\n",
      "\t(No symbol) [0x00007FF796C3A814]\n",
      "\t(No symbol) [0x00007FF796C3A9AD]\n",
      "\t(No symbol) [0x00007FF796C2A199]\n",
      "\tBaseThreadInitThunk [0x00007FFB9355259D+29]\n",
      "\tRtlUserThreadStart [0x00007FFB9444AF38+40]\n",
      "\n"
     ]
    },
    {
     "ename": "NoSuchWindowException",
     "evalue": "Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=131.0.6778.85)\nStacktrace:\n\tGetHandleVerifier [0x00007FF796CC6CB5+28821]\n\t(No symbol) [0x00007FF796C33840]\n\t(No symbol) [0x00007FF796AD578A]\n\t(No symbol) [0x00007FF796AAF4F5]\n\t(No symbol) [0x00007FF796B56247]\n\t(No symbol) [0x00007FF796B6ECE2]\n\t(No symbol) [0x00007FF796B4F0A3]\n\t(No symbol) [0x00007FF796B1A778]\n\t(No symbol) [0x00007FF796B1B8E1]\n\tGetHandleVerifier [0x00007FF796FFFCAD+3408013]\n\tGetHandleVerifier [0x00007FF79701741F+3504127]\n\tGetHandleVerifier [0x00007FF79700B5FD+3455453]\n\tGetHandleVerifier [0x00007FF796D8BDBB+835995]\n\t(No symbol) [0x00007FF796C3EB5F]\n\t(No symbol) [0x00007FF796C3A814]\n\t(No symbol) [0x00007FF796C3A9AD]\n\t(No symbol) [0x00007FF796C2A199]\n\tBaseThreadInitThunk [0x00007FFB9355259D+29]\n\tRtlUserThreadStart [0x00007FFB9444AF38+40]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchWindowException\u001b[0m                     Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10696\\2579131870.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;31m# 构建目标URL\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[0mtest_url\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf'https://www.xiaohongshu.com/discovery/item/{code}'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m     \u001b[0mbrowser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;31m# 等待页面加载完成\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m    354\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m         \u001b[1;34m\"\"\"Loads a web page in the current browser session.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 356\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGET\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"url\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    357\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    345\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    346\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 347\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    348\u001b[0m             \u001b[0mresponse\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"value\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_unwrap_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"value\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    349\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    227\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"alert\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"text\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 229\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNoSuchWindowException\u001b[0m: Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=131.0.6778.85)\nStacktrace:\n\tGetHandleVerifier [0x00007FF796CC6CB5+28821]\n\t(No symbol) [0x00007FF796C33840]\n\t(No symbol) [0x00007FF796AD578A]\n\t(No symbol) [0x00007FF796AAF4F5]\n\t(No symbol) [0x00007FF796B56247]\n\t(No symbol) [0x00007FF796B6ECE2]\n\t(No symbol) [0x00007FF796B4F0A3]\n\t(No symbol) [0x00007FF796B1A778]\n\t(No symbol) [0x00007FF796B1B8E1]\n\tGetHandleVerifier [0x00007FF796FFFCAD+3408013]\n\tGetHandleVerifier [0x00007FF79701741F+3504127]\n\tGetHandleVerifier [0x00007FF79700B5FD+3455453]\n\tGetHandleVerifier [0x00007FF796D8BDBB+835995]\n\t(No symbol) [0x00007FF796C3EB5F]\n\t(No symbol) [0x00007FF796C3A814]\n\t(No symbol) [0x00007FF796C3A9AD]\n\t(No symbol) [0x00007FF796C2A199]\n\tBaseThreadInitThunk [0x00007FFB9355259D+29]\n\tRtlUserThreadStart [0x00007FFB9444AF38+40]\n"
     ]
    }
   ],
   "source": [
    "# 检查已有的 items 数据\n",
    "if os.path.exists('_items.txt'):\n",
    "    with open('_items.txt', 'r', encoding='utf-8') as f:\n",
    "        items = f.readlines()\n",
    "    items = [json.loads(item.strip()) for item in items]\n",
    "    itemCodeList = [item['code'] for item in items]\n",
    "else:\n",
    "    itemCodeList = []\n",
    "\n",
    "# 检查已有的详情数据\n",
    "if os.path.exists('_items_detail.txt'):\n",
    "    with open('_items_detail.txt', 'r', encoding='utf-8') as f:\n",
    "        items_detail = f.readlines()\n",
    "    items_detail = [json.loads(item.strip()) for item in items_detail]\n",
    "    itemCodeList_detail = [item['code'] for item in items_detail]\n",
    "else:\n",
    "    itemCodeList_detail = []\n",
    "\n",
    "# 开始解析\n",
    "qbar = tqdm(total=len(items))\n",
    "for item in items:\n",
    "    code = item['code']\n",
    "    if code in itemCodeList_detail:\n",
    "        continue\n",
    "    \n",
    "    # 构建目标URL\n",
    "    test_url = f'https://www.xiaohongshu.com/discovery/item/{code}'\n",
    "    browser.get(test_url)\n",
    "\n",
    "    # 等待页面加载完成\n",
    "    try:\n",
    "        WebDriverWait(browser, 10).until(\n",
    "            EC.presence_of_element_located((By.XPATH, '//*[@class=\"list-container\"]'))\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load page for code {code}: {e}\")\n",
    "        continue\n",
    "\n",
    "    # 获取页面源代码\n",
    "    html = browser.page_source\n",
    "    selector = Selector(text=html)\n",
    "\n",
    "    try:\n",
    "        # 提取详情信息\n",
    "        item['title2'] = selector.xpath('//*[@name=\"og:title\"]/@content').extract_first()\n",
    "        item['description'] = selector.xpath('//*[@name=\"description\"]/@content').extract_first()\n",
    "        item['keywords'] = selector.xpath('//*[@name=\"keywords\"]/@content').extract_first()\n",
    "        item['type'] = selector.xpath('//*[@name=\"og:type\"]/@content').extract_first()\n",
    "        item['image'] = selector.xpath('//*[@name=\"og:image\"]/@content').extract_first()\n",
    "        item['url'] = selector.xpath('//*[@name=\"og:url\"]/@content').extract_first()\n",
    "\n",
    "        # 提取评论信息\n",
    "        comments_data = []\n",
    "        comments = selector.xpath('//div[@class=\"parent-comment\"]')\n",
    "        for comment in comments:\n",
    "            try:\n",
    "                user_name = comment.xpath('.//div[@class=\"author\"]/a[@class=\"name\"]/text()').get()\n",
    "                comment_text = comment.xpath('.//div[@class=\"content\"]//span[@class=\"note-text\"]/span/text()').getall()\n",
    "                comment_text = ''.join(comment_text)  # 拼接评论文本\n",
    "                location = comment.xpath('.//div[@class=\"info\"]//span[@class=\"location\"]/text()').get()\n",
    "                \n",
    "                comments_data.append({\n",
    "                    'user_name': user_name,\n",
    "                    'comment_text': comment_text,\n",
    "                    'location': location\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"Error parsing comment for code {code}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        # 添加评论数据到 item\n",
    "        item['comments'] = comments_data\n",
    "\n",
    "        # 保存数据\n",
    "        with open('_items_detail.txt', 'a+', encoding='utf-8') as f:\n",
    "            f.write(json.dumps(item, ensure_ascii=False) + '\\n')\n",
    "        itemCodeList_detail.append(code)\n",
    "\n",
    "        qbar.update(1)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to parse item {code}: {e}\")\n",
    "        continue\n",
    "\n",
    "    time.sleep(1)\n",
    "\n",
    "# 完成\n",
    "qbar.close()\n",
    "print(\"Crawling completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 四、数据分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 已经存储的详情页\n",
    "if os.path.exists('_items_detail.txt'):\n",
    "    with open('_items_detail.txt', 'r', encoding='utf-8') as f:\n",
    "        items_detail = f.readlines()\n",
    "    items_detail = [json.loads(item.strip()) for item in items_detail]\n",
    "    \n",
    "import pandas as pd\n",
    "df_detail = pd.DataFrame(items_detail)\n",
    "\n",
    "keywordsList = df_detail['keywords'].to_list()\n",
    "keywordsList = [i.split(',') for i in keywordsList]\n",
    "\n",
    "\n",
    "\n",
    "# 展平列表，对关键词进行计数\n",
    "keywordsALL = [item for sublist in keywordsList for item in sublist]\n",
    "\n",
    "\n",
    "\n",
    "# 看每一个关键词的数量\n",
    "counts = {}\n",
    "for i in keywordsALL:\n",
    "    if i in counts.keys():\n",
    "        counts[i] += 1\n",
    "    else:\n",
    "        counts[i] = 1\n",
    "\n",
    "\n",
    "\n",
    "df = pd.DataFrame(counts.items(), columns=['keywords', 'counts'])\n",
    "df.sort_values(by='counts', ascending=False, inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "完整代码（不包括detial部分）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Nov 24 12:06:35 2024 : 登录成功！！！\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing item: Missing href\n",
      "Error parsing item: Missing href\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 17/20 [00:05<00:00,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing item: Missing href\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:10<00:00,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling completed! Total items saved: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from tqdm import tqdm\n",
    "from scrapy.selector import Selector\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "\n",
    "# 用户输入\n",
    "text = input(\"请输入要搜索的关键词: \")\n",
    "totalnum = int(input(\"请输入要爬取的帖子数量: \"))\n",
    "\n",
    "# 文件名设置\n",
    "output_file = f\"{text}_{totalnum}_items.txt\"\n",
    "\n",
    "# Selenium 配置\n",
    "options = Options()\n",
    "options.add_experimental_option('debuggerAddress', '127.0.0.1:9222')\n",
    "options.add_argument('--incognito')  # 无痕模式\n",
    "options.add_argument('blink-settings=imagesEnabled=false')  # 不加载图片\n",
    "service = Service(\"C:/Users/lenovo/Desktop/xiaohongshu/chromedriver.exe\")  # 替换为实际路径\n",
    "browser = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "# 打开小红书搜索页面\n",
    "browser.get('https://www.xiaohongshu.com/explore')\n",
    "\n",
    "# 判断是否登录\n",
    "while True:\n",
    "    page_source = browser.page_source\n",
    "    if '登录探索更多内容' in page_source:\n",
    "        print('%s : 未登录，请手动登录小红书！！！' % time.ctime())\n",
    "        time.sleep(2)\n",
    "    else:\n",
    "        print('%s : 登录成功！！！' % time.ctime())\n",
    "        time.sleep(3)\n",
    "        break\n",
    "\n",
    "# 打开搜索结果页面\n",
    "url = f'https://www.xiaohongshu.com/search_result?keyword={text}&source=web_explore_feed'\n",
    "browser.get(url)\n",
    "time.sleep(3)\n",
    "\n",
    "# 加载已有数据\n",
    "if os.path.exists(output_file):\n",
    "    with open(output_file, 'r', encoding='utf-8') as f:\n",
    "        items = [json.loads(item.strip()) for item in f.readlines() if item.strip()]\n",
    "    itemCodeList = [item['code'] for item in items]\n",
    "else:\n",
    "    items = []\n",
    "    itemCodeList = []\n",
    "\n",
    "# 设置进度条\n",
    "remaining_items = totalnum - len(itemCodeList)\n",
    "qbar = tqdm(total=remaining_items)\n",
    "\n",
    "# 解析网页内容\n",
    "def parsePage(text):\n",
    "    global items  # 确保更新到全局变量\n",
    "    selector = Selector(text=text)\n",
    "    divs = selector.xpath('//section[contains(@class, \"note-item\")]')\n",
    "    if not divs:\n",
    "        print(\"No items found on page.\")\n",
    "        return\n",
    "\n",
    "    for div in divs:\n",
    "        if len(items) >= totalnum:  # 检查是否达到爬取目标数量\n",
    "            break\n",
    "\n",
    "        item = {}\n",
    "        try:\n",
    "            # 提取信息\n",
    "            item['title'] = div.xpath('.//a[@class=\"title\"]/span/text()').extract_first()\n",
    "            item['user'] = div.xpath('.//a[@class=\"author\"]//span[@class=\"name\"]/text()').extract_first()\n",
    "            like_num = div.xpath('.//span[@class=\"count\"]/text()').extract_first()\n",
    "            item['likeNum'] = like_num.strip() if like_num else \"0\"\n",
    "            \n",
    "            # 提取 href\n",
    "            href = div.xpath('.//a[@class=\"cover mask\"]/@href').extract_first()\n",
    "            if not href:\n",
    "                href = div.xpath('.//a/@href').extract_first()\n",
    "            if not href:\n",
    "                print(\"Error parsing item: Missing href\")\n",
    "                continue\n",
    "            item['code'] = href.split('/')[-1]\n",
    "\n",
    "            # 保存数据\n",
    "            if item['code'] not in itemCodeList:\n",
    "                itemCodeList.append(item['code'])\n",
    "                items.append(item)\n",
    "                with open(output_file, 'a+', encoding='utf-8') as f:\n",
    "                    f.write(json.dumps(item, ensure_ascii=False) + '\\n')\n",
    "                qbar.update(1)\n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing item: {e}\")\n",
    "\n",
    "# 爬取数据\n",
    "while len(items) < totalnum:\n",
    "    if '- THE END -' in browser.page_source:\n",
    "        print('- THE END -')\n",
    "        break\n",
    "\n",
    "    parsePage(text=browser.page_source)\n",
    "    time.sleep(random.uniform(1, 3))  # 添加随机延迟\n",
    "    browser.execute_script('window.scrollTo(0, document.body.scrollHeight)')\n",
    "    time.sleep(random.uniform(2, 4))\n",
    "\n",
    "qbar.close()\n",
    "print(f\"Crawling completed! Total items saved: {len(items)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Nov 24 12:05:18 2024 : 登录成功！！！\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/102 [04:13<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing item: Missing href in div: <section data-v-14f91c23=\"\" data-v-7aab4d45=\"\" class=\"note-item\" data-index=\"5\" style=\"--53f1d28e: 252.66666666666666px; --2db87601: 16px; --1013328c: blur(42.5px); transform: translate(276.667px, 440px);\"><div data-v-14f91c23=\"\"><div data-v-f2b40456=\"\" data-v-14f91c23=\"\" class=\"query-note-wrapper\" style=\"--2054e94c: rgba(51, 51, 51, 0.80); --c165635e: rgba(222, 229, 240, 1); --b3e6f99e: rgba(51, 51, 51, 1); --c90bc876: rgba(235, 242, 250, 1); --43b33e67: rgba(66, 97, 125, 1);\"><div data-v-f2b40456=\"\" class=\"query-note-header\"><div data-v-f2b40456=\"\" class=\"icon-warpper\"><svg data-v-23d27ada=\"\" data-v-f2b40456=\"\" class=\"reds-icon\" width=\"20\" height=\"20\"><use data-v-23d27ada=\"\" xlink:href=\"#search\"></use></svg></div><span data-v-f2b40456=\"\" class=\"query-note-header-text\">相关搜索</span><!----></div><div data-v-f2b40456=\"\" class=\"query-note-list\"><div data-v-f2b40456=\"\" class=\"query-note-item\"><div data-v-f2b40456=\"\" class=\"item-wrapper rec-query\"><!----><span data-v-f2b40456=\"\" class=\"item-text\">wang是什么牌子</span></div></div><div data-v-f2b40456=\"\" class=\"query-note-item\"><div data-v-f2b40456=\"\" class=\"item-wrapper rec-query\"><!----><span data-v-f2b40456=\"\" class=\"item-text\">wang logo</span></div></div><div data-v-f2b40456=\"\" class=\"query-note-item\"><div data-v-f2b40456=\"\" class=\"item-wrapper rec-query\"><!----><span data-v-f2b40456=\"\" class=\"item-text\">wang大王</span></div></div><div data-v-f2b40456=\"\" class=\"query-note-item\"><div data-v-f2b40456=\"\" class=\"item-wrapper rec-query\"><!----><span data-v-f2b40456=\"\" class=\"item-text\">亚历山大wang</span></div></div></div><!----></div></div></section>\n",
      "Error parsing item: Missing href in div: <section data-v-14f91c23=\"\" data-v-7aab4d45=\"\" class=\"note-item\" data-index=\"15\" style=\"--53f1d28e: 252.66666666666666px; --2db87601: 16px; --1013328c: blur(42.5px); transform: translate(553.333px, 1948px);\"><div data-v-14f91c23=\"\"><div data-v-f2b40456=\"\" data-v-14f91c23=\"\" class=\"query-note-wrapper\" style=\"--2054e94c: rgba(51, 51, 51, 0.80); --c165635e: rgba(222, 229, 240, 1); --b3e6f99e: rgba(51, 51, 51, 1); --c90bc876: rgba(235, 242, 250, 1); --43b33e67: rgba(66, 97, 125, 1);\"><div data-v-f2b40456=\"\" class=\"query-note-header\"><div data-v-f2b40456=\"\" class=\"icon-warpper\"><svg data-v-23d27ada=\"\" data-v-f2b40456=\"\" class=\"reds-icon\" width=\"20\" height=\"20\"><use data-v-23d27ada=\"\" xlink:href=\"#search\"></use></svg></div><span data-v-f2b40456=\"\" class=\"query-note-header-text\">相关搜索</span><!----></div><div data-v-f2b40456=\"\" class=\"query-note-list\"><div data-v-f2b40456=\"\" class=\"query-note-item\"><div data-v-f2b40456=\"\" class=\"item-wrapper rec-query\"><!----><span data-v-f2b40456=\"\" class=\"item-text\">a wang</span></div></div><div data-v-f2b40456=\"\" class=\"query-note-item\"><div data-v-f2b40456=\"\" class=\"item-wrapper rec-query\"><!----><span data-v-f2b40456=\"\" class=\"item-text\">wang衣服是什么牌子</span></div></div><div data-v-f2b40456=\"\" class=\"query-note-item\"><div data-v-f2b40456=\"\" class=\"item-wrapper rec-query\"><!----><span data-v-f2b40456=\"\" class=\"item-text\">wang品牌</span></div></div><div data-v-f2b40456=\"\" class=\"query-note-item\"><div data-v-f2b40456=\"\" class=\"item-wrapper rec-query\"><!----><span data-v-f2b40456=\"\" class=\"item-text\">s.wang</span></div></div></div><!----></div></div></section>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing item: Missing href in div: <section data-v-14f91c23=\"\" data-v-7aab4d45=\"\" class=\"note-item\" data-index=\"15\" style=\"--53f1d28e: 252.66666666666666px; --2db87601: 16px; --1013328c: blur(42.5px); transform: translate(553.333px, 1948px);\"><div data-v-14f91c23=\"\"><div data-v-f2b40456=\"\" data-v-14f91c23=\"\" class=\"query-note-wrapper\" style=\"--2054e94c: rgba(51, 51, 51, 0.80); --c165635e: rgba(222, 229, 240, 1); --b3e6f99e: rgba(51, 51, 51, 1); --c90bc876: rgba(235, 242, 250, 1); --43b33e67: rgba(66, 97, 125, 1);\"><div data-v-f2b40456=\"\" class=\"query-note-header\"><div data-v-f2b40456=\"\" class=\"icon-warpper\"><svg data-v-23d27ada=\"\" data-v-f2b40456=\"\" class=\"reds-icon\" width=\"20\" height=\"20\"><use data-v-23d27ada=\"\" xlink:href=\"#search\"></use></svg></div><span data-v-f2b40456=\"\" class=\"query-note-header-text\">相关搜索</span><!----></div><div data-v-f2b40456=\"\" class=\"query-note-list\"><div data-v-f2b40456=\"\" class=\"query-note-item\"><div data-v-f2b40456=\"\" class=\"item-wrapper rec-query\"><!----><span data-v-f2b40456=\"\" class=\"item-text\">a wang</span></div></div><div data-v-f2b40456=\"\" class=\"query-note-item\"><div data-v-f2b40456=\"\" class=\"item-wrapper rec-query\"><!----><span data-v-f2b40456=\"\" class=\"item-text\">wang衣服是什么牌子</span></div></div><div data-v-f2b40456=\"\" class=\"query-note-item\"><div data-v-f2b40456=\"\" class=\"item-wrapper rec-query\"><!----><span data-v-f2b40456=\"\" class=\"item-text\">wang品牌</span></div></div><div data-v-f2b40456=\"\" class=\"query-note-item\"><div data-v-f2b40456=\"\" class=\"item-wrapper rec-query\"><!----><span data-v-f2b40456=\"\" class=\"item-text\">s.wang</span></div></div></div><!----></div></div></section>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:10<00:00,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling completed! Total items saved: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#加入反扒\n",
    "# \"C:\\Users\\lenovo\\Desktop\\chrome-win64\\chrome.exe\" --remote-debugging-port=9222 --user-data-dir=\"C:\\selenum\\AutomationProfile\"\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from scrapy.selector import Selector\n",
    "\n",
    "# 用户输入\n",
    "text = input(\"请输入要搜索的关键词: \")\n",
    "totalnum = int(input(\"请输入要爬取的帖子数量: \"))\n",
    "\n",
    "# 文件名设置\n",
    "output_file = f\"{text}_{totalnum}_items.txt\"\n",
    "output_detail_file = f\"{text}_{totalnum}_items_detail.txt\"\n",
    "\n",
    "# 初始化 Selenium\n",
    "def init_browser():\n",
    "    options = Options()\n",
    "    options.add_experimental_option('debuggerAddress', '127.0.0.1:9222')\n",
    "    options.add_argument('--incognito')  # 无痕模式\n",
    "    options.add_argument('--disable-blink-features=AutomationControlled')  # 反自动化检测\n",
    "    options.add_argument('blink-settings=imagesEnabled=false')  # 不加载图片\n",
    "    options.add_argument(f'user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.150 Safari/537.36')\n",
    "    service = Service(\"C:/Users/lenovo/Desktop/xiaohongshu/chromedriver.exe\")  # 替换为实际路径\n",
    "    browser = webdriver.Chrome(service=service, options=options)\n",
    "    \n",
    "    # 注入反检测脚本\n",
    "    stealth_js = \"\"\"\n",
    "    Object.defineProperty(navigator, 'webdriver', {get: () => undefined});\n",
    "    window.navigator.chrome = { runtime: {} };\n",
    "    Object.defineProperty(navigator, 'plugins', {get: () => [1, 2, 3, 4, 5]});\n",
    "    Object.defineProperty(navigator, 'languages', {get: () => ['en-US', 'en']});\n",
    "    \"\"\"\n",
    "    browser.execute_cdp_cmd(\"Page.addScriptToEvaluateOnNewDocument\", {\"source\": stealth_js})\n",
    "    return browser\n",
    "\n",
    "browser = init_browser()\n",
    "\n",
    "# 打开小红书搜索页面\n",
    "browser.get('https://www.xiaohongshu.com/explore')\n",
    "\n",
    "# 判断是否登录\n",
    "while True:\n",
    "    page_source = browser.page_source\n",
    "    if '登录探索更多内容' in page_source:\n",
    "        print('%s : 未登录，请手动登录小红书！！！' % time.ctime())\n",
    "        time.sleep(2)\n",
    "    else:\n",
    "        print('%s : 登录成功！！！' % time.ctime())\n",
    "        time.sleep(3)\n",
    "        break\n",
    "\n",
    "# 打开搜索结果页面\n",
    "url = f'https://www.xiaohongshu.com/search_result?keyword={text}&source=web_explore_feed'\n",
    "browser.get(url)\n",
    "time.sleep(3)\n",
    "\n",
    "# 加载已有数据\n",
    "if os.path.exists(output_file):\n",
    "    with open(output_file, 'r', encoding='utf-8') as f:\n",
    "        items = [json.loads(item.strip()) for item in f.readlines() if item.strip()]\n",
    "    itemCodeList = [item['code'] for item in items]\n",
    "else:\n",
    "    items = []\n",
    "    itemCodeList = []\n",
    "\n",
    "if os.path.exists(output_detail_file):\n",
    "    with open(output_detail_file, 'r', encoding='utf-8') as f:\n",
    "        items_detail = [json.loads(item.strip()) for item in f.readlines() if item.strip()]\n",
    "    itemCodeList_detail = [item['code'] for item in items_detail]\n",
    "else:\n",
    "    items_detail = []\n",
    "    itemCodeList_detail = []\n",
    "\n",
    "# 设置进度条\n",
    "remaining_items = totalnum - len(itemCodeList)\n",
    "qbar = tqdm(total=remaining_items)\n",
    "\n",
    "# 解析网页内容\n",
    "def parsePage(text):\n",
    "    global items  # 确保更新到全局变量\n",
    "    selector = Selector(text=text)\n",
    "    divs = selector.xpath('//section[contains(@class, \"note-item\")]')\n",
    "    if not divs:\n",
    "        print(\"No items found on page.\")\n",
    "        return\n",
    "\n",
    "    for div in divs:\n",
    "        if len(items) >= totalnum:  # 检查是否达到爬取目标数量\n",
    "            break\n",
    "\n",
    "        item = {}\n",
    "        try:\n",
    "            # 提取信息\n",
    "            item['title'] = div.xpath('.//a[@class=\"title\"]/span/text()').extract_first()\n",
    "            item['user'] = div.xpath('.//a[@class=\"author\"]//span[@class=\"name\"]/text()').extract_first()\n",
    "            like_num = div.xpath('.//span[@class=\"count\"]/text()').extract_first()\n",
    "            item['likeNum'] = like_num.strip() if like_num else \"0\"\n",
    "            \n",
    "            # 提取 href\n",
    "            href = div.xpath('.//a[@class=\"cover mask\"]/@href').extract_first()\n",
    "            if not href:\n",
    "                href = div.xpath('.//a/@href').extract_first()\n",
    "            if not href:\n",
    "                print(f\"Error parsing item: Missing href in div: {div.extract()}\")\n",
    "                continue\n",
    "            item['code'] = href.split('/')[-1]\n",
    "\n",
    "            # 保存数据\n",
    "            if item['code'] not in itemCodeList:\n",
    "                itemCodeList.append(item['code'])\n",
    "                items.append(item)\n",
    "                with open(output_file, 'a+', encoding='utf-8') as f:\n",
    "                    f.write(json.dumps(item, ensure_ascii=False) + '\\n')\n",
    "                qbar.update(1)\n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing item: {e}\")\n",
    "\n",
    "# 爬取数据\n",
    "while len(items) < totalnum:\n",
    "    if '- THE END -' in browser.page_source:\n",
    "        print('- THE END -')\n",
    "        break\n",
    "\n",
    "    parsePage(text=browser.page_source)\n",
    "    time.sleep(random.uniform(1, 3))\n",
    "    browser.execute_script('window.scrollTo(0, document.body.scrollHeight)')\n",
    "    time.sleep(random.uniform(2, 4))\n",
    "\n",
    "qbar.close()\n",
    "print(f\"Crawling completed! Total items saved: {len(items)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load page for code 64c527d3000000001700ed8a: Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF796CC6CB5+28821]\n",
      "\t(No symbol) [0x00007FF796C33840]\n",
      "\t(No symbol) [0x00007FF796AD578A]\n",
      "\t(No symbol) [0x00007FF796B291BE]\n",
      "\t(No symbol) [0x00007FF796B294AC]\n",
      "\t(No symbol) [0x00007FF796B72647]\n",
      "\t(No symbol) [0x00007FF796B4F33F]\n",
      "\t(No symbol) [0x00007FF796B6F412]\n",
      "\t(No symbol) [0x00007FF796B4F0A3]\n",
      "\t(No symbol) [0x00007FF796B1A778]\n",
      "\t(No symbol) [0x00007FF796B1B8E1]\n",
      "\tGetHandleVerifier [0x00007FF796FFFCAD+3408013]\n",
      "\tGetHandleVerifier [0x00007FF79701741F+3504127]\n",
      "\tGetHandleVerifier [0x00007FF79700B5FD+3455453]\n",
      "\tGetHandleVerifier [0x00007FF796D8BDBB+835995]\n",
      "\t(No symbol) [0x00007FF796C3EB5F]\n",
      "\t(No symbol) [0x00007FF796C3A814]\n",
      "\t(No symbol) [0x00007FF796C3A9AD]\n",
      "\t(No symbol) [0x00007FF796C2A199]\n",
      "\tBaseThreadInitThunk [0x00007FFB9355259D+29]\n",
      "\tRtlUserThreadStart [0x00007FFB9444AF38+40]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load page for code 649c1e74000000001300e49b: Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF796CC6CB5+28821]\n",
      "\t(No symbol) [0x00007FF796C33840]\n",
      "\t(No symbol) [0x00007FF796AD578A]\n",
      "\t(No symbol) [0x00007FF796B291BE]\n",
      "\t(No symbol) [0x00007FF796B294AC]\n",
      "\t(No symbol) [0x00007FF796B72647]\n",
      "\t(No symbol) [0x00007FF796B4F33F]\n",
      "\t(No symbol) [0x00007FF796B6F412]\n",
      "\t(No symbol) [0x00007FF796B4F0A3]\n",
      "\t(No symbol) [0x00007FF796B1A778]\n",
      "\t(No symbol) [0x00007FF796B1B8E1]\n",
      "\tGetHandleVerifier [0x00007FF796FFFCAD+3408013]\n",
      "\tGetHandleVerifier [0x00007FF79701741F+3504127]\n",
      "\tGetHandleVerifier [0x00007FF79700B5FD+3455453]\n",
      "\tGetHandleVerifier [0x00007FF796D8BDBB+835995]\n",
      "\t(No symbol) [0x00007FF796C3EB5F]\n",
      "\t(No symbol) [0x00007FF796C3A814]\n",
      "\t(No symbol) [0x00007FF796C3A9AD]\n",
      "\t(No symbol) [0x00007FF796C2A199]\n",
      "\tBaseThreadInitThunk [0x00007FFB9355259D+29]\n",
      "\tRtlUserThreadStart [0x00007FFB9444AF38+40]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load page for code 647fff9d0000000013010294: Message: no such window: target window already closed\n",
      "from unknown error: web view not found\n",
      "  (Session info: chrome=131.0.6778.85)\n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF796CC6CB5+28821]\n",
      "\t(No symbol) [0x00007FF796C33840]\n",
      "\t(No symbol) [0x00007FF796AD578A]\n",
      "\t(No symbol) [0x00007FF796AAF4F5]\n",
      "\t(No symbol) [0x00007FF796B56247]\n",
      "\t(No symbol) [0x00007FF796B6ECE2]\n",
      "\t(No symbol) [0x00007FF796B4F0A3]\n",
      "\t(No symbol) [0x00007FF796B1A778]\n",
      "\t(No symbol) [0x00007FF796B1B8E1]\n",
      "\tGetHandleVerifier [0x00007FF796FFFCAD+3408013]\n",
      "\tGetHandleVerifier [0x00007FF79701741F+3504127]\n",
      "\tGetHandleVerifier [0x00007FF79700B5FD+3455453]\n",
      "\tGetHandleVerifier [0x00007FF796D8BDBB+835995]\n",
      "\t(No symbol) [0x00007FF796C3EB5F]\n",
      "\t(No symbol) [0x00007FF796C3A814]\n",
      "\t(No symbol) [0x00007FF796C3A9AD]\n",
      "\t(No symbol) [0x00007FF796C2A199]\n",
      "\tBaseThreadInitThunk [0x00007FFB9355259D+29]\n",
      "\tRtlUserThreadStart [0x00007FFB9444AF38+40]\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_24180\\2840081071.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[1;31m# 爬取详情页数据\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m     \u001b[0mcrawl_details\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_24180\\2840081071.py\u001b[0m in \u001b[0;36mcrawl_details\u001b[1;34m()\u001b[0m\n\u001b[0;32m    104\u001b[0m         \u001b[0mparse_detail\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'code'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m         \u001b[0mqbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m         \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# 避免过快请求被封\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m     \u001b[0mqbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "##运行_items获得_items_detailed\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from scrapy.selector import Selector\n",
    "\n",
    "# 文件名设置\n",
    "output_items_file = \"_items.txt\"\n",
    "output_details_file = \"_items_detail.txt\"\n",
    "\n",
    "# 初始化 Selenium\n",
    "def init_browser():\n",
    "    options = Options()\n",
    "    options.add_experimental_option('debuggerAddress', '127.0.0.1:9222')\n",
    "    options.add_argument('--disable-blink-features=AutomationControlled')  # 防止被检测\n",
    "    options.add_argument('--incognito')  # 无痕模式\n",
    "    service_path = \"C:/Users/lenovo/Desktop/xiaohongshu/chromedriver.exe\"  # 替换为实际路径\n",
    "    service = webdriver.chrome.service.Service(service_path)\n",
    "    browser = webdriver.Chrome(service=service, options=options)\n",
    "    return browser\n",
    "\n",
    "browser = init_browser()\n",
    "\n",
    "# 加载已有的 items 和详情数据\n",
    "def load_existing_data():\n",
    "    if os.path.exists(output_items_file):\n",
    "        with open(output_items_file, 'r', encoding='utf-8') as f:\n",
    "            items = [json.loads(line.strip()) for line in f if line.strip()]\n",
    "    else:\n",
    "        items = []\n",
    "\n",
    "    if os.path.exists(output_details_file):\n",
    "        with open(output_details_file, 'r', encoding='utf-8') as f:\n",
    "            items_detail = [json.loads(line.strip()) for line in f if line.strip()]\n",
    "    else:\n",
    "        items_detail = []\n",
    "\n",
    "    itemCodeList = [item['code'] for item in items]\n",
    "    itemCodeList_detail = [item['code'] for item in items_detail]\n",
    "\n",
    "    return items, items_detail, itemCodeList, itemCodeList_detail\n",
    "\n",
    "items, items_detail, itemCodeList, itemCodeList_detail = load_existing_data()\n",
    "\n",
    "# 爬取单个详情页数据\n",
    "def parse_detail(code):\n",
    "    test_url = f'https://www.xiaohongshu.com/discovery/item/{code}'\n",
    "    try:\n",
    "        browser.get(test_url)\n",
    "        WebDriverWait(browser, 10).until(\n",
    "            EC.presence_of_element_located((By.XPATH, '//*[@class=\"list-container\"]'))\n",
    "        )\n",
    "        html = browser.page_source\n",
    "        selector = Selector(text=html)\n",
    "\n",
    "        item_detail = {\n",
    "            'code': code,\n",
    "            'title': selector.xpath('//*[@name=\"og:title\"]/@content').get(),\n",
    "            'description': selector.xpath('//*[@name=\"description\"]/@content').get(),\n",
    "            'keywords': selector.xpath('//*[@name=\"keywords\"]/@content').get(),\n",
    "            'type': selector.xpath('//*[@name=\"og:type\"]/@content').get(),\n",
    "            'image': selector.xpath('//*[@name=\"og:image\"]/@content').get(),\n",
    "            'url': selector.xpath('//*[@name=\"og:url\"]/@content').get(),\n",
    "            'comments': []\n",
    "        }\n",
    "\n",
    "        # 提取评论信息\n",
    "        comments = selector.xpath('//div[@class=\"parent-comment\"]')\n",
    "        for comment in comments:\n",
    "            try:\n",
    "                user_name = comment.xpath('.//div[@class=\"author\"]/a[@class=\"name\"]/text()').get()\n",
    "                comment_text = ''.join(comment.xpath('.//div[@class=\"content\"]//span[@class=\"note-text\"]/span/text()').getall()).strip()\n",
    "                location = comment.xpath('.//div[@class=\"info\"]//span[@class=\"location\"]/text()').get()\n",
    "                item_detail['comments'].append({\n",
    "                    'user_name': user_name,\n",
    "                    'comment_text': comment_text,\n",
    "                    'location': location\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"Error parsing comment for code {code}: {e}\")\n",
    "                continue\n",
    "\n",
    "        # 保存详情数据\n",
    "        with open(output_details_file, 'a+', encoding='utf-8') as f:\n",
    "            f.write(json.dumps(item_detail, ensure_ascii=False) + '\\n')\n",
    "        itemCodeList_detail.append(code)\n",
    "\n",
    "        print(f\"Saved details for code {code}, with {len(item_detail['comments'])} comments.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load page for code {code}: {e}\")\n",
    "\n",
    "# 主程序：爬取 items 的详情数据\n",
    "def crawl_details():\n",
    "    global items\n",
    "    remaining_items = [item for item in items if item['code'] not in itemCodeList_detail]\n",
    "    qbar = tqdm(total=len(remaining_items))\n",
    "\n",
    "    for item in remaining_items:\n",
    "        parse_detail(item['code'])\n",
    "        qbar.update(1)\n",
    "        time.sleep(2)  # 避免过快请求被封\n",
    "\n",
    "    qbar.close()\n",
    "    print(\"Details crawling completed!\")\n",
    "\n",
    "# 输入要爬取的网址或直接运行\n",
    "if __name__ == \"__main__\":\n",
    "    # 爬取详情页数据\n",
    "    crawl_details()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功加载 10 条帖子信息。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load page for https://www.xiaohongshu.com/discovery/item/64561f370000000013007e99: Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF796CC6CB5+28821]\n",
      "\t(No symbol) [0x00007FF796C33840]\n",
      "\t(No symbol) [0x00007FF796AD578A]\n",
      "\t(No symbol) [0x00007FF796B291BE]\n",
      "\t(No symbol) [0x00007FF796B294AC]\n",
      "\t(No symbol) [0x00007FF796B72647]\n",
      "\t(No symbol) [0x00007FF796B4F33F]\n",
      "\t(No symbol) [0x00007FF796B6F412]\n",
      "\t(No symbol) [0x00007FF796B4F0A3]\n",
      "\t(No symbol) [0x00007FF796B1A778]\n",
      "\t(No symbol) [0x00007FF796B1B8E1]\n",
      "\tGetHandleVerifier [0x00007FF796FFFCAD+3408013]\n",
      "\tGetHandleVerifier [0x00007FF79701741F+3504127]\n",
      "\tGetHandleVerifier [0x00007FF79700B5FD+3455453]\n",
      "\tGetHandleVerifier [0x00007FF796D8BDBB+835995]\n",
      "\t(No symbol) [0x00007FF796C3EB5F]\n",
      "\t(No symbol) [0x00007FF796C3A814]\n",
      "\t(No symbol) [0x00007FF796C3A9AD]\n",
      "\t(No symbol) [0x00007FF796C2A199]\n",
      "\tBaseThreadInitThunk [0x00007FFB9355259D+29]\n",
      "\tRtlUserThreadStart [0x00007FFB9444AF38+40]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:14<02:06, 14.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load page for https://www.xiaohongshu.com/discovery/item/664d578c000000001501009e: Message: no such window: target window already closed\n",
      "from unknown error: web view not found\n",
      "  (Session info: chrome=131.0.6778.85)\n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF796CC6CB5+28821]\n",
      "\t(No symbol) [0x00007FF796C33840]\n",
      "\t(No symbol) [0x00007FF796AD578A]\n",
      "\t(No symbol) [0x00007FF796AAF4F5]\n",
      "\t(No symbol) [0x00007FF796B56247]\n",
      "\t(No symbol) [0x00007FF796B6ECE2]\n",
      "\t(No symbol) [0x00007FF796B4F0A3]\n",
      "\t(No symbol) [0x00007FF796B1A778]\n",
      "\t(No symbol) [0x00007FF796B1B8E1]\n",
      "\tGetHandleVerifier [0x00007FF796FFFCAD+3408013]\n",
      "\tGetHandleVerifier [0x00007FF79701741F+3504127]\n",
      "\tGetHandleVerifier [0x00007FF79700B5FD+3455453]\n",
      "\tGetHandleVerifier [0x00007FF796D8BDBB+835995]\n",
      "\t(No symbol) [0x00007FF796C3EB5F]\n",
      "\t(No symbol) [0x00007FF796C3A814]\n",
      "\t(No symbol) [0x00007FF796C3A9AD]\n",
      "\t(No symbol) [0x00007FF796C2A199]\n",
      "\tBaseThreadInitThunk [0x00007FFB9355259D+29]\n",
      "\tRtlUserThreadStart [0x00007FFB9444AF38+40]\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_24180\\3069390159.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_24180\\3069390159.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    100\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdetails_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'a+'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m                     \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdetail\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_ascii\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m             \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# 避免过快请求被封\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m             \u001b[0mqbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m         \u001b[0mqbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "##关键字不行，但是单个网站可以（这是整合部分）\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from scrapy.selector import Selector\n",
    "\n",
    "# 初始化 Selenium\n",
    "def init_browser():\n",
    "    options = Options()\n",
    "    options.add_experimental_option('debuggerAddress', '127.0.0.1:9222')\n",
    "    options.add_argument('--disable-blink-features=AutomationControlled')  # 防止被检测\n",
    "    options.add_argument('--incognito')  # 无痕模式\n",
    "    service_path = \"C:/Users/lenovo/Desktop/xiaohongshu/chromedriver.exe\"  # 替换为实际路径\n",
    "    service = webdriver.chrome.service.Service(service_path)\n",
    "    browser = webdriver.Chrome(service=service, options=options)\n",
    "    return browser\n",
    "\n",
    "browser = init_browser()\n",
    "\n",
    "# 加载已有数据\n",
    "def load_existing_data(filename):\n",
    "    if os.path.exists(filename):\n",
    "        with open(filename, 'r', encoding='utf-8') as f:\n",
    "            return [json.loads(line.strip()) for line in f if line.strip()]\n",
    "    return []\n",
    "\n",
    "# 爬取单个详情页数据\n",
    "def parse_detail(url, max_comments):\n",
    "    try:\n",
    "        browser.get(url)\n",
    "        WebDriverWait(browser, 10).until(\n",
    "            EC.presence_of_element_located((By.XPATH, '//*[@class=\"list-container\"]'))\n",
    "        )\n",
    "        html = browser.page_source\n",
    "        selector = Selector(text=html)\n",
    "\n",
    "        item_detail = {\n",
    "            'url': url,\n",
    "            'title': selector.xpath('//*[@name=\"og:title\"]/@content').get(),\n",
    "            'description': selector.xpath('//*[@name=\"description\"]/@content').get(),\n",
    "            'keywords': selector.xpath('//*[@name=\"keywords\"]/@content').get(),\n",
    "            'type': selector.xpath('//*[@name=\"og:type\"]/@content').get(),\n",
    "            'image': selector.xpath('//*[@name=\"og:image\"]/@content').get(),\n",
    "            'comments': []\n",
    "        }\n",
    "\n",
    "        # 提取评论信息\n",
    "        comments = selector.xpath('//div[@class=\"parent-comment\"]')\n",
    "        for i, comment in enumerate(comments):\n",
    "            if i >= max_comments:  # 限制评论数量\n",
    "                break\n",
    "            try:\n",
    "                user_name = comment.xpath('.//div[@class=\"author\"]/a[@class=\"name\"]/text()').get()\n",
    "                comment_text = ''.join(comment.xpath('.//div[@class=\"content\"]//span[@class=\"note-text\"]/span/text()').getall()).strip()\n",
    "                location = comment.xpath('.//div[@class=\"info\"]//span[@class=\"location\"]/text()').get()\n",
    "                item_detail['comments'].append({\n",
    "                    'user_name': user_name,\n",
    "                    'comment_text': comment_text,\n",
    "                    'location': location\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"Error parsing comment for {url}: {e}\")\n",
    "\n",
    "        print(f\"Saved details for URL {url}, with {len(item_detail['comments'])} comments.\")\n",
    "        return item_detail\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load page for {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "# 主函数\n",
    "def main():\n",
    "    user_input = input(\"请输入关键字或网址: \").strip()\n",
    "    max_comments = int(input(\"请输入每条需要的评论量: \"))\n",
    "\n",
    "    # 如果输入的是关键字\n",
    "    if \"http\" not in user_input:\n",
    "        items_file = f\"{user_input}_items.txt\"\n",
    "        items = load_existing_data(items_file)\n",
    "        if not items:\n",
    "            print(f\"未找到文件: {items_file}，请确认关键字是否正确。\")\n",
    "            return\n",
    "        print(f\"成功加载 {len(items)} 条帖子信息。\")\n",
    "        \n",
    "        details_file = f\"{user_input}_items_detail.txt\"\n",
    "        processed_urls = [item['url'] for item in load_existing_data(details_file)]\n",
    "        qbar = tqdm(total=len(items))\n",
    "\n",
    "        # 爬取详情数据\n",
    "        for item in items:\n",
    "            url = f\"https://www.xiaohongshu.com/discovery/item/{item['code']}\"\n",
    "            if url in processed_urls:\n",
    "                continue\n",
    "            detail = parse_detail(url, max_comments)\n",
    "            if detail:\n",
    "                with open(details_file, 'a+', encoding='utf-8') as f:\n",
    "                    f.write(json.dumps(detail, ensure_ascii=False) + '\\n')\n",
    "            time.sleep(2)  # 避免过快请求被封\n",
    "            qbar.update(1)\n",
    "        qbar.close()\n",
    "        print(\"关键字爬取完成！\")\n",
    "\n",
    "    # 如果输入的是网址\n",
    "    else:\n",
    "        details_file = \"_items_detail.txt\"\n",
    "        print(f\"处理单个网址: {user_input}\")\n",
    "        detail = parse_detail(user_input, max_comments)\n",
    "        if detail:\n",
    "            with open(details_file, 'a+', encoding='utf-8') as f:\n",
    "                f.write(json.dumps(detail, ensure_ascii=False) + '\\n')\n",
    "        print(\"单个网址爬取完成！\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
